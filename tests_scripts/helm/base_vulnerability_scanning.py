from ensurepip import version
import time
import requests
from systest_utils import statics, Logger, TestUtil
from tests_scripts.helm.base_helm import BaseHelm
import random
import yaml
import base64
from pkg_resources import parse_version

_UNSET_DATE = "0001-01-01T00:00:00Z"


class BaseVulnerabilityScanning(BaseHelm):
    def __init__(self, test_obj=None, backend=None, kubernetes_obj=None, test_driver=None):
        super(BaseVulnerabilityScanning, self).__init__(test_driver=test_driver, test_obj=test_obj, backend=backend,
                                                        kubernetes_obj=kubernetes_obj)
        self.ignore_agent = True
        self.ignore_ca_logs = True

    def cleanup(self, **kwargs):
        super().cleanup(**kwargs)
        return statics.SUCCESS, ""

    def test_cluster_deleted(self, since_time: str):
        cluster_result, _ = self.wait_for_report(report_type=self.backend.get_scan_results_sum_summary, namespace='',
                                                 expected_results=0, since_time=since_time, expected_status_code=404,
                                                 cluster_name=self.kubernetes_obj.get_cluster_name(), timeout=600)
        assert cluster_result, 'Failed to verify deleting cluster {x} from backend'. \
            format(x=self.kubernetes_obj.get_cluster_name())

    @staticmethod
    def test_total_is_rce_count(be_summary: dict):
        for container_scan in be_summary:
            rce_fix_count = 0
            for severity in container_scan['severitiesStats']:
                rce_fix_count += severity['rceFixCount']
            assert rce_fix_count == container_scan['rceFixCount']
      
    @staticmethod
    def count_containers_with_severity(be_summary: dict, severityLvl: str, fixable: bool = False):
        count = 0
        for container_scan in be_summary:        
            for severity in container_scan['severitiesStats']:
                if fixable and severity['fixedTotal'] < 1:
                    continue
                if severity['severity'] != severityLvl:
                    continue
                count += 1
        return count
        
    @staticmethod
    def test_no_errors_in_scan_result(be_summary: dict):
        for scan in be_summary:
            assert scan[statics.SCAN_RESULT_STATUS_FIELD] != 'Error', \
                'container {container_name} received from backend with {num} error: {error_lst}'.format(
                    container_name=scan[statics.SCAN_RESULT_CONTAINER_NAME_FIELD],
                    num=len(scan[statics.SCAN_RESULT_ERRORS_FIELD]),
                    error_lst=scan[statics.SCAN_RESULT_ERRORS_FIELD]
                )

    def test_expected_scan_result(self, containers_cve: dict):
        expected_results = self.create_vulnerabilities_expected_results(
            expected_results=self.test_obj.get_arg('expected_results'))
        failed_paths = []
        for container_name, cve_list in expected_results.items():
            assert container_name in containers_cve.keys(), \
                f"Expect to receive {container_name} in results_details from backend"
            for cve in cve_list:
                if cve not in containers_cve[container_name].keys():
                    failed_paths.append(f"{container_name} -> {cve}")

        assert not failed_paths, 'Expect the data from backend would not fail less CVEs then the expected results.\n' \
                                 f'in the following entries is happened:\nfailed_paths: {failed_paths}\n containers_cve: {containers_cve}'

    def test_expected_scan_registry_result(self, containers_cve: dict):
        expected_results = self.create_vulnerabilities_expected_results(
            expected_results=self.test_obj.get_arg('expected_results'))
        failed_paths = []
        for container_name, cve_list in expected_results.items():
            image = [image_name for image_name in containers_cve.keys() if container_name in image_name]
            for cve in cve_list:
                if cve not in containers_cve[image[0]].keys():
                    failed_paths.append(f"{container_name} -> {cve}")

        assert not failed_paths, 'Expect the data from backend would not fail less CVEs then the expected results.\n' \
                                 f'in the following entries is happened:\nfailed_paths: {failed_paths}\n containers_cve: {containers_cve}'

    def test_applied_cve_exceptions(self, namespace, cve_exception_guid, cves_list, since_time):
        be_summary = self.backend.get_scan_results_sum_summary(
                                             namespace=namespace, since_time=since_time,
                                             expected_results=self.get_expected_number_of_pods(
                                                 namespace=namespace))

        containers_scan_id = self.get_container_scan_id(be_summary=be_summary)
        containers_cve = self.get_container_cve_without_filter_response(since_time=since_time,
                                                                        container_scan_id=containers_scan_id)

        # 5.2 test applied cve exceptions in report 
        self.test_applied_cve_exceptions_in_report(containers_cve=containers_cve, cve_exception_guid=cve_exception_guid,
                                                    cves_list=cves_list)
        # 5.3 test ignore rules summary in report
        self.test_cve_ignore_rule_summary_in_report(containers_cve=containers_cve, cve_exception_guid=cve_exception_guid,
                                                    cves_list=cves_list)
                                                    
        return None

    @staticmethod
    def test_applied_cve_exceptions_in_report(containers_cve, cve_exception_guid, cves_list):
        result = []
        for cve in cves_list:
            found = False
            for container_name in containers_cve:
                for container_cve in containers_cve[container_name]:
                    if cve == container_cve["name"] and "exceptionApplied" in container_cve:
                        for cve_exception_applied in container_cve["exceptionApplied"]:
                            if cve_exception_applied["guid"] == cve_exception_guid:
                                for inner_cve in cve_exception_applied["vulnerabilities"]:
                                    if inner_cve["name"] == cve:
                                        found = True
                                        break
                if found:
                    break
            if not found:
                result.append(cve)
        assert not result, "test_applied_cve_exceptions failed, not found cvs the applied: {}".format(result)
        
    @staticmethod
    def test_cve_ignore_rule_summary_in_report(containers_cve, cve_exception_guid, cves_list):
        result = []
        for cve in cves_list:
            found = False
            for container_name in containers_cve:
                for container_cve in containers_cve[container_name]:
                    if cve == container_cve["name"] and "ignoreRulesSummary" in container_cve:
                        ignore_rules_summary = container_cve["ignoreRulesSummary"]
                        if ignore_rules_summary[cve] and cve_exception_guid in ignore_rules_summary[cve]["ignoreRulesIDs"]:
                            found = True
                            break
                if found:
                    break
            if not found:
                result.append(cve)
        assert not result, "test_applied_cve_ignore_rule_summary_in_report failed, not found cvs the ignore rules summary: {}".format(result)

    def test_no_errors_in_armo_system_logs(self):
        pass
        # TODO: We cannot simply search the logs for the word "error", we need to find a better solution
        # error_logs = self.get_errors_in_armo_system_logs()
        # assert not error_logs, 'There are errors obtained from the armo-system component logs:/n' + error_logs

    @staticmethod
    def get_error_message_of_compare(header: str, body: str, failed_result: dict):
        result_msg = header
        for k, v in failed_result.items():
            result_msg += body.format(x=v[0], y=v[1], z=k)
        return result_msg

    @staticmethod
    def get_container_scan_id(be_summary: dict):
        return list(map(lambda x: (x[statics.SCAN_RESULT_CONTAINER_NAME_FIELD],
                                   x[statics.SCAN_RESULT_CONTAINER_SCAN_ID_FIELD],
                                   x[statics.SCAN_RESULT_TOTAL_FIELD]), be_summary))

    @staticmethod
    def get_image_scan_id(be_summary: dict):
        return list(map(lambda x: (x[statics.SCAN_RESULT_IMAGE_TAG_NAME_FIELD],
                                   x[statics.SCAN_RESULT_CONTAINER_SCAN_ID_FIELD],
                                   x[statics.SCAN_RESULT_TOTAL_FIELD]), be_summary))

    @staticmethod
    def get_scan_id(be_summary: dict):
        return be_summary[0][statics.SCAN_RESULT_CONTAINER_SCAN_ID_FIELD]

    def test_cve_result(self, since_time: str, containers_scan_id, be_summary, timeout: int = 600):

        start = time.time()
        err = ""
        success = False
        while time.time() - start < timeout:
            Logger.logger.info('wait for detailed CVE aggregation to end in backend')
            try:
                containers_cve = self.get_container_cve(since_time=since_time, container_scan_id=containers_scan_id)
                Logger.logger.info('Test results against expected results')
                self.test_expected_scan_result(containers_cve=containers_cve)
                success = True
                break
            except Exception as e:
                if str(e).find("502 Bad Gateway") > 0:
                    raise e
                err = e
                Logger.logger.warning(
                    "timeout {} since_time {} containers_scan_id {} error: {}".format(timeout // 60, since_time,
                                                                                      containers_scan_id, err))
            time.sleep(30)
        if not success:
            raise Exception(
                f"test_cve_result, timeout: {timeout // 60} minutes, error: {err}. ")

        Logger.logger.info('Test backend results_details against results_sum_summary')
        self.test_results_details_against_results_sum_summary(containers_cve=containers_cve, be_summary=be_summary)

    def test_registry_cve_result(self, since_time: str, containers_scan_id, be_summary, timeout: int = 600):

        start = time.time()
        err = ""
        success = False
        while time.time() - start < timeout:
            Logger.logger.info('wait for detailed CVE aggregation to end in backend')
            try:
                containers_cve = self.get_registry_container_cve(since_time=since_time,
                                                                 container_scan_id=containers_scan_id)
                Logger.logger.info('Test results against expected results')
                self.test_expected_scan_registry_result(containers_cve=containers_cve)
                success = True
                break
            except Exception as e:
                if str(e).find("502 Bad Gateway") > 0:
                    raise e
                err = e
                Logger.logger.warning(
                    "timeout {} since_time {} containers_scan_id {} error: {}".format(timeout // 60, since_time,
                                                                                      containers_scan_id, err))
            time.sleep(30)
        if not success:
            raise Exception(
                f"test_cve_result, timeout: {timeout // 60} minutes, error: {err}. ")

        Logger.logger.info('Test backend results_details against results_sum_summary')
        self.test_results_details_against_results_sum_summary(containers_cve=containers_cve, be_summary=be_summary)

    def get_container_cve(self, since_time: str, container_scan_id):
        """
        params:
            container_scan_id: list of tuples.. [(container-name, container-scan-id), ...]
        return:
            dict of dict: {container-name: dict-of-CVEs, ...}
                dict-of-CVEs contains:{CVE-name: {severity: value, isRce: true/false}}
        """
        expected_results = self.create_vulnerabilities_expected_results(
            expected_results=self.test_obj.get_arg('expected_results'))

        _CONTAINER_NAME = 0
        _CONTAINER_SCAN_ID = 1
        _CONTAINER_TOTAL_CVE = 2
        if isinstance(container_scan_id, tuple):
            container_scan_id = [container_scan_id]
            return self.get_container_cve(since_time=since_time, container_scan_id=container_scan_id)

        result = {}
        for container in container_scan_id:
            container_cve, time = self.wait_for_report(timeout=800, report_type=self.backend.get_scan_results_details,
                                                       containers_scan_id=container[_CONTAINER_SCAN_ID],
                                                       since_time=since_time,
                                                       expected_results=expected_results[container[_CONTAINER_NAME]],
                                                       total_cve=container[_CONTAINER_TOTAL_CVE])
            Logger.logger.info(
                "before processing: container {} has CVEs {}".format(container[_CONTAINER_NAME], container_cve))
            name = statics.SCAN_RESULT_NAME_FIELD
            severity = statics.SCAN_RESULT_SEVERITY_FIELD
            is_rce = statics.SCAN_RESULT_IS_RCE_FIELD
            categories = statics.SCAN_RESULT_CATEGORIES_FIELD
            total_count = statics.SCAN_RESULT_TOTAL_FIELD
            rce_count =  statics.SCAN_RESULT_RCETOTAL_FIELD

            container_cve_dict = {}
            for item in container_cve:
                is_rce_cve = item[categories][is_rce]
                if item[name] in container_cve_dict:
                    container_cve_dict[item[name]][total_count] += 1
                    if is_rce_cve:
                        container_cve_dict[item[name]][rce_count] += 1
                else:
                    container_cve_dict[item[name]] = {severity: item[severity], is_rce: item[categories][is_rce],
                                                     total_count: 1, rce_count: 1 if is_rce_cve else 0}
            
            result[container[_CONTAINER_NAME]] = container_cve_dict
            Logger.logger.info(
                "after processing: container {} has CVEs {}".format(container[_CONTAINER_NAME], container_cve_dict))

        return result

    def get_registry_container_cve(self, since_time: str, container_scan_id):
        """
        params:
            container_scan_id: list of tuples.. [(container-name, container-scan-id), ...]
        return:
            dict of dict: {container-name: dict-of-CVEs, ...}
                dict-of-CVEs contains:{CVE-name: {severity: value, isRce: true/false}}
        """

        _IMAGE_TAG_NAME = 0
        _IMAGE_TAG_SCAN_ID = 1
        _IMAGE_TAG_TOTAL_CVE = 2
        if isinstance(container_scan_id, tuple):
            container_scan_id = [container_scan_id]
            return self.get_registry_container_cve(since_time=since_time, container_scan_id=container_scan_id)

        result = {}
        for container in container_scan_id:
            container_cve, time = self.wait_for_report(timeout=600, report_type=self.backend.get_registry_container_cve,
                                                       containers_scan_id=container[_IMAGE_TAG_SCAN_ID],
                                                       since_time=since_time, total_cve=container[_IMAGE_TAG_TOTAL_CVE])
            name = statics.SCAN_RESULT_NAME_FIELD
            severity = statics.SCAN_RESULT_SEVERITY_FIELD
            is_rce = statics.SCAN_RESULT_IS_RCE_FIELD
            categories = statics.SCAN_RESULT_CATEGORIES_FIELD
            container_cve = {i[name]: {severity: i[severity], is_rce: i[categories][is_rce]} for i in container_cve}
            result[container[_IMAGE_TAG_NAME]] = container_cve
            Logger.logger.info("container {} has cves {}".format(container[_IMAGE_TAG_NAME], container_cve))

        return result

    def test_all_images_vuln_scan_reported(self, in_cluster_images, since_time):
        for ns in in_cluster_images:
            be_summary, _ = self.wait_for_report(timeout=1200, report_type=self.backend.get_scan_results_sum_summary,
                                                 namespace=ns, since_time=since_time,
                                                 expected_results=len(in_cluster_images[ns]))

    def get_container_cve_without_filter_response(self, since_time: str, container_scan_id):
        expected_results = self.create_vulnerabilities_expected_results(
            expected_results=self.test_obj.get_arg('expected_results'))

        _CONTAINER_NAME = 0
        _CONTAINER_SCAN_ID = 1
        _CONTAINER_TOTAL_CVE = 2
        if isinstance(container_scan_id, tuple):
            container_scan_id = [container_scan_id]
            return self.get_container_cve(since_time=since_time, container_scan_id=container_scan_id)

        result = {}
        for container in container_scan_id:
            container_cve, time = self.wait_for_report(timeout=600, report_type=self.backend.get_scan_results_details,
                                                       containers_scan_id=container[_CONTAINER_SCAN_ID],
                                                       since_time=since_time,
                                                       expected_results=expected_results[container[_CONTAINER_NAME]],
                                                       total_cve=container[_CONTAINER_TOTAL_CVE])
            result[container[_CONTAINER_NAME]] = container_cve

        return result

    @staticmethod
    def test_results_details_against_results_sum_summary(containers_cve: dict, be_summary: list):

        containers_severity = {}
        for name, cve_dict in containers_cve.items():
            containers_severity[name] = {statics.SCAN_RESULT_RCETOTAL_FIELD: 0, statics.SCAN_RESULT_TOTAL_FIELD: 0}
            for cve, details in cve_dict.items():
                containers_severity[name][statics.SCAN_RESULT_RCETOTAL_FIELD] += details[statics.SCAN_RESULT_RCETOTAL_FIELD]
                containers_severity[name][statics.SCAN_RESULT_TOTAL_FIELD] += details[statics.SCAN_RESULT_TOTAL_FIELD]
                if details[statics.SCAN_RESULT_SEVERITY_FIELD] not in containers_severity[name]:
                    containers_severity[name][details[statics.SCAN_RESULT_SEVERITY_FIELD]] = 0
                containers_severity[name][details[statics.SCAN_RESULT_SEVERITY_FIELD]] += details[statics.SCAN_RESULT_TOTAL_FIELD]

        for container in be_summary:
            message = 'It is expected that the data from results_sum_summary and the data from results_details will ' \
                      'be the same, in this case they are different. In container {x}, from results_sum_summary ' \
                      '{x1} = {x2} and from results_details {x1} = {y2}'
            container_severity_key = container[statics.SCAN_RESULT_CONTAINER_NAME_FIELD]
            if container_severity_key == '':
                container_severity_key = container['imageTag']

            assert container[statics.SCAN_RESULT_TOTAL_FIELD] == \
                   containers_severity[container_severity_key][statics.SCAN_RESULT_TOTAL_FIELD], \
                message.format(x=container[statics.SCAN_RESULT_CONTAINER_NAME_FIELD],
                               x1=statics.SCAN_RESULT_TOTAL_FIELD,
                               x2=container[statics.SCAN_RESULT_TOTAL_FIELD],
                               y2=containers_severity[container_severity_key][
                                   statics.SCAN_RESULT_TOTAL_FIELD])
            assert container[statics.SCAN_RESULT_RCETOTAL_FIELD] == \
                   containers_severity[container_severity_key][
                       statics.SCAN_RESULT_RCETOTAL_FIELD], \
                message.format(x=container[statics.SCAN_RESULT_CONTAINER_NAME_FIELD],
                               x1=statics.SCAN_RESULT_RCETOTAL_FIELD,
                               x2=container[statics.SCAN_RESULT_RCETOTAL_FIELD],
                               y2=containers_severity[container_severity_key][
                                   statics.SCAN_RESULT_RCETOTAL_FIELD])

            for severity in container[statics.SCAN_RESULT_SEVERITIES_STATS_FIELD]:
                assert severity[statics.SCAN_RESULT_TOTAL_FIELD] == \
                       containers_severity[container_severity_key][
                           severity[statics.SCAN_RESULT_SEVERITY_FIELD]], \
                    message.format(x=container[statics.SCAN_RESULT_CONTAINER_NAME_FIELD],
                                   x1=statics.SCAN_RESULT_SEVERITIES_STATS_FIELD + '->' + severity[
                                       statics.SCAN_RESULT_SEVERITY_FIELD] + '->' + statics.SCAN_RESULT_TOTAL_FIELD,
                                   x2=severity[statics.SCAN_RESULT_TOTAL_FIELD],
                                   y2=containers_severity[container_severity_key][
                                       severity[statics.SCAN_RESULT_SEVERITY_FIELD]])

    def test_cluster_info(self):
        cluster_info = self.get_cluster_with_risk_status(cluster_name=self.kubernetes_obj.get_cluster_name())
        Logger.logger.info("cluster_info: %s", cluster_info)
        helm_chart_version = cluster_info['helmChartVersion']
        assert helm_chart_version != ''
        assert cluster_info['firstConnected'] != _UNSET_DATE
        assert cluster_info['lastReconnected'] != _UNSET_DATE
        assert cluster_info['lastDisconnected'] == _UNSET_DATE
        assert cluster_info['disconnectionCount'] == 0
        assert cluster_info['connectionCount'] == 1
        assert parse_version(cluster_info['helmChartVersionInfo']['latest']) <= parse_version(self.get_latest_helm_version()), f"cluster_info: {cluster_info['helmChartVersionInfo']['latest']}, helm version: {self.get_latest_helm_version()}"
        assert parse_version(helm_chart_version) >= parse_version(cluster_info['helmChartVersionInfo']['current']) , f"cluster_info: {helm_chart_version}, helm version: {cluster_info['helmChartVersionInfo']['current']}"
        assert parse_version(cluster_info['latestHelmChartVersion']) <= parse_version(self.get_latest_helm_version()) , f"cluster_info: {cluster_info['latestHelmChartVersion']}, helm version: {self.get_latest_helm_version()}"
        assert cluster_info['attributes']['numberOfWorkerNodes'] != 0
        assert cluster_info['attributes']['numberOfWorkerNodes'] <= cluster_info['attributes']['workerNodes']['max']
        assert cluster_info['attributes']['alias'] != ''
        assert cluster_info['attributes']['kind'] == 'k8s', 'The cluster kind is not k8s'
        assert cluster_info['attributes']['description'] == 'created by Kubescape automatically', \
            'The cluster description is not created by Kubescape automatically'
        assert cluster_info['attributes']['createdBy'] == 'armo-aggregator', \
            'The cluster created by is not armo-aggregator'
        assert 'latest' in cluster_info['kubescapeVersion'], f"invalid cluster_info {cluster_info}"
        assert parse_version(cluster_info['kubescapeVersion']['latest']) <= parse_version(
            self.get_latest_kubescape_version()), f"cluster_info: {cluster_info['kubescapeVersion']['latest']}, kubescape version: {self.get_latest_kubescape_version()}"
        Logger.logger.debug("test_cluster_info passed")

    def get_cluster_with_risk_status(self, cluster_name: str):
        cluster_info, t = self.wait_for_report(report_type=self.backend.get_cluster_with_risk_status,
                                               cluster_name=cluster_name)
        return cluster_info

    def get_cluster_info(self, cluster_name: str):
        cluster_info, t = self.wait_for_report(report_type=self.backend.get_cluster, cluster_name=cluster_name)
        return cluster_info

    def get_latest_helm_version(self):
        download_url = 'https://raw.githubusercontent.com/kubescape/helm-charts/gh-pages/index.yaml'
        helm_index = yaml.load(requests.get(download_url).content, Loader=yaml.FullLoader)
        version = "undefined"
        if "entries" in helm_index and "kubescape-cloud-operator" in helm_index["entries"]:
            if len(helm_index["entries"]["kubescape-cloud-operator"]) > 0:
                version = helm_index["entries"]["kubescape-cloud-operator"][0]["version"]

        return version

    def get_latest_kubescape_version(self):
        download_url = 'https://api.github.com/repos/kubescape/kubescape/releases/latest'
        version = self.get_latest_version(download_url)
        return version

    def get_latest_version(self, url):
        res = requests.get(url).json()
        return res['tag_name']

    def get_some_cve_exceptions_list(self, container_name):
        expected_results = self.create_vulnerabilities_expected_results(
            expected_results=self.test_obj.get_arg('expected_results'))
        return expected_results[container_name][:random.randint(1, 5)]

    def test_delete_vuln_scan_cronjob(self, cron_job: dict):
        self.backend.delete_vuln_scan_cronjob(cj=cron_job)
        TestUtil.sleep(30, "wait till delete cronjob will arrive to backend")
        cj, t = self.wait_for_report(report_type=self.backend.get_vuln_scan_cronjob, cj_name=cron_job['name'],
                                     expect_to_results=False)
        assert not cj, f"Failed to verify from backend the cronjob was deleted, cronjob: {cj}"

    def test_delete_registry_scan_cronjob(self, cron_job: dict, credentials: dict = None):
        self.backend.delete_registry_scan_cronjob(cj=cron_job)

        TestUtil.sleep(30, "wait till delete cronjob will arrive to backend")

        # check that the cronjob was deleted from cluster
        cj = self.kubernetes_obj.run(self.kubernetes_obj.client_BatchV1beta1Api.read_namespaced_cron_job,
                                     namespace=statics.CA_NAMESPACE_FROM_HELM_NAME, name=cron_job['name'])
        assert len(cj) == 0 \
            , "Cronjob {}  was not deleted in cluster".format(cron_job['name'])

        # check that the configmap was deleted from cluster
        configmap = self.kubernetes_obj.run(self.kubernetes_obj.client_CoreV1Api.read_namespaced_config_map,
                                            namespace=statics.CA_NAMESPACE_FROM_HELM_NAME, name=cron_job['name'])
        assert len(configmap) == 0 \
            , "Configmap with for {} cronjob was not deleted in cluster".format(cron_job['name'])

        if credentials is not None and credentials['password'] != '':
            # check that the secret was deleted from cluster
            secret = self.kubernetes_obj.run(self.kubernetes_obj.client_CoreV1Api.read_namespaced_secret,
                                             namespace=statics.CA_NAMESPACE_FROM_HELM_NAME, name=cron_job['name'])
            assert len(secret) == 0 \
                , "Secret with for {} cronjob was not deleted in cluster".format(cron_job['name'])

        # check that cronjob was deleted from be
        cj, t = self.wait_for_report(report_type=self.backend.get_registry_scan_cronjob, cj_name=cron_job['name'],
                                     expect_to_results=False)
        assert not cj, f"Failed to verify from backend the cronjob was deleted, cronjob: {cj}"

    def test_delete_registry_scan_cronjob_deprecated(self, cron_job: dict):
        self.backend.delete_registry_scan_cronjob_deprecated(cj=cron_job)
        TestUtil.sleep(30, "wait till delete cronjob will arrive to backend")
        cj, t = self.wait_for_report(report_type=self.backend.get_registry_scan_cronjob, cj_name=cron_job['name'],
                                     expect_to_results=False)
        assert not cj, f"Failed to verify from backend the cronjob was deleted, cronjob: {cj}"

    def test_update_vuln_scan_cronjob(self, cron_job: dict, schedule_string: str):
        cron_job[statics.CA_VULN_SCAN_CRONJOB_CRONTABSCHEDULE_FILED] = schedule_string
        self.backend.update_vuln_scan_cronjob(cj=cron_job)
        TestUtil.sleep(30, "wait till update cronjob will arrive to backend")

        new_cj, t = self.wait_for_report(report_type=self.backend.get_vuln_scan_cronjob, cj_name=cron_job['name'])
        assert new_cj[statics.CA_VULN_SCAN_CRONJOB_CRONTABSCHEDULE_FILED] == schedule_string, \
            f'Failed to verify that cronjob {cron_job["name"]} with schedule {schedule_string} was updated. ' \
            f'cronjob: {new_cj}'
        assert (new_cj[statics.CA_VULN_SCAN_CRONJOB_NAME_FILED].startswith("kubevuln")), \
            f'cronjob {cron_job["name"]} has wrong label for {statics.CA_VULN_SCAN_CRONJOB_NAME_FILED}. '
        return new_cj

    def test_update_registry_scan_cronjob(self, cron_job: dict, schedule_string: str, depth: int, auth_method=None):
        self.backend.update_registry_scan_cronjob(cluster_name=self.kubernetes_obj.get_cluster_name(),
                                                  registry_name=cron_job['registryName'],
                                                  registry_type=cron_job['registryType'],
                                                  cron_tab_schedule=schedule_string, cj_name=cron_job['name'],
                                                  cj_id=cron_job['id'], depth=depth, auth_method=auth_method)

        TestUtil.sleep(30, "wait till update cronjob will arrive to backend")

        # check that configmap was updated in cluster
        configmap = self.kubernetes_obj.run(self.kubernetes_obj.client_CoreV1Api.read_namespaced_config_map,
                                            namespace=statics.CA_NAMESPACE_FROM_HELM_NAME, name=cron_job['name'])
        assert f'"depth":{depth}' in configmap.data['request-body.json'], \
            f'configmap {cron_job["name"]} has wrong depth: expected {depth}, configmap: {configmap.data["request-body.json"]}.  '

        if auth_method is not None:
            # check that secret was updated in cluster
            secret = self.kubernetes_obj.run(self.kubernetes_obj.client_CoreV1Api.read_namespaced_secret,
                                             namespace=statics.CA_NAMESPACE_FROM_HELM_NAME, name=cron_job
                ['name'])

            username = auth_method['username']
            password = auth_method['password']
            registries_auth = secret.data['registriesAuth']
            registries_auth = base64.b64decode(registries_auth).decode()
            assert f'"username":"{username}"' in registries_auth, \
                f'secret {cron_job["name"]} has wrong username: expected {username}, registries_auth: {registries_auth}.  '

            assert f'"password":"{password}"' in registries_auth, \
                f'secret {cron_job["name"]} has wrong password: expected {password}, registries_auth: {registries_auth}.  '

        # check that cronjob was updated in be
        new_cj, t = self.wait_for_report(report_type=self.backend.get_registry_scan_cronjob, cj_name=cron_job['name'])
        assert new_cj[statics.CA_VULN_SCAN_CRONJOB_CRONTABSCHEDULE_FILED] == schedule_string, \
            f'Failed to verify that cronjob {cron_job["name"]} with schedule {schedule_string} was updated. ' \
            f'cronjob: {new_cj}'
        assert new_cj['depth'] == depth, \
            f'Failed to verify that cronjob {cron_job["name"]} with depth {depth} was updated. ' \
            f'cronjob: {new_cj}'
        assert (new_cj[statics.CA_VULN_SCAN_CRONJOB_NAME_FILED].startswith("kubescape-registry-scan")), \
            f'cronjob {cron_job["name"]} has wrong name for {statics.CA_VULN_SCAN_CRONJOB_NAME_FILED}. '

        return new_cj

    def test_update_registry_scan_cronjob_deprecated(self, cron_job: dict, schedule_string: str):
        cron_job[statics.CA_VULN_SCAN_CRONJOB_CRONTABSCHEDULE_FILED] = schedule_string
        self.backend.update_registry_scan_cronjob_deprecated(cj=cron_job)
        TestUtil.sleep(30, "wait till update cronjob will arrive to backend")

        new_cj, t = self.wait_for_report(report_type=self.backend.get_registry_scan_cronjob, cj_name=cron_job['name'])
        assert new_cj[statics.CA_VULN_SCAN_CRONJOB_CRONTABSCHEDULE_FILED] == schedule_string, \
            f'Failed to verify that cronjob {cron_job["name"]} with schedule {schedule_string} was updated. ' \
            f'cronjob: {new_cj}'
        assert (new_cj[statics.CA_VULN_SCAN_CRONJOB_NAME_FILED].startswith("kubescape-registry-scan")), \
            f'cronjob {cron_job["name"]} has wrong name for {statics.CA_VULN_SCAN_CRONJOB_NAME_FILED}. '
        return new_cj

    def test_create_vuln_scan_cronjob(self, namespaces_list: list, schedule_string: str):
        old_expected_cjs = self.kubernetes_obj.get_vuln_scan_cronjob()
        old_actual_cjs, t = self.wait_for_report(report_type=self.backend.get_vuln_scan_cronjob_list,
                                                 expected_cjs=old_expected_cjs,
                                                 cluster_name=self.kubernetes_obj.get_cluster_name())

        self.backend.create_vuln_scan_job_request(cluster_name=self.kubernetes_obj.get_cluster_name(),
                                                  schedule_string=schedule_string, namespaces_list=namespaces_list)
        TestUtil.sleep(30, "wait till cronjob will arrive to backend")
        new_expected_cjs = self.kubernetes_obj.get_vuln_scan_cronjob()
        new_actual_cjs, t = self.wait_for_report(report_type=self.backend.get_vuln_scan_cronjob_list,
                                                 expected_cjs=new_expected_cjs,
                                                 cluster_name=self.kubernetes_obj.get_cluster_name())

        new_cj = self.get_new_cronjob(old_cronjob_list=old_actual_cjs, new_cronjob_list=new_actual_cjs)
        assert new_cj, f"Failed to find the new cronjob, old_cronjob_list: {old_actual_cjs}. " \
                       f"new_cronjob_list: {new_actual_cjs}"

        return new_cj

    def test_create_registry_scan_cronjob_deprecated(self, registry_name: str, schedule_string: str):
        old_expected_cjs = self.kubernetes_obj.get_registry_scan_cronjob()
        old_actual_cjs, t = self.wait_for_report(report_type=self.backend.get_registry_scan_cronjob_list,
                                                 expected_cjs=old_expected_cjs,
                                                 cluster_name=self.kubernetes_obj.get_cluster_name())

        resp = self.backend.create_registry_scan_job_request_deprecated(
            cluster_name=self.kubernetes_obj.get_cluster_name(),
            schedule_string=schedule_string, registry_name=registry_name)

        TestUtil.sleep(30, "wait till cronjob will arrive to backend")
        new_expected_cjs = self.kubernetes_obj.get_registry_scan_cronjob()
        new_actual_cjs, t = self.wait_for_report(report_type=self.backend.get_registry_scan_cronjob_list,
                                                 expected_cjs=new_expected_cjs,
                                                 cluster_name=self.kubernetes_obj.get_cluster_name())

        new_cj = self.get_new_cronjob(old_cronjob_list=old_actual_cjs, new_cronjob_list=new_actual_cjs)
        assert new_cj, f"Failed to find the new cronjob, old_cronjob_list: {old_actual_cjs}. " \
                       f"new_cronjob_list: {new_actual_cjs}"

        return new_cj

    def test_create_registry_scan_cronjob(self, registry_name: str, schedule_string: str, credentials: dict):
        old_expected_cjs = self.kubernetes_obj.get_registry_scan_cronjob()
        old_actual_cjs, t = self.wait_for_report(report_type=self.backend.get_registry_scan_cronjob_list,
                                                 expected_cjs=old_expected_cjs,
                                                 cluster_name=self.kubernetes_obj.get_cluster_name())
        if credentials is not None:
            auth_method = {"type": "private", "username": credentials["username"], "password": credentials["password"]}
            registry_type = "private"
        else:
            auth_method = {"type": "public", "username": "", "password": ""}
            registry_type = "public"
        self.backend.create_registry_scan_job_request(cluster_name=self.kubernetes_obj.get_cluster_name(),
                                                      schedule_string=schedule_string, registry_name=registry_name,
                                                      auth_method=auth_method, registry_type=registry_type)

        TestUtil.sleep(30, "wait till cronjob will arrive to backend")
        new_expected_cjs = self.kubernetes_obj.get_registry_scan_cronjob()
        new_actual_cjs, t = self.wait_for_report(report_type=self.backend.get_registry_scan_cronjob_list,
                                                 expected_cjs=new_expected_cjs,
                                                 cluster_name=self.kubernetes_obj.get_cluster_name())

        new_cj = self.get_new_cronjob(old_cronjob_list=old_actual_cjs, new_cronjob_list=new_actual_cjs)
        assert new_cj, f"Failed to find the new cronjob, old_cronjob_list: {old_actual_cjs}. " \
                       f"new_cronjob_list: {new_actual_cjs}"

        return new_cj

    @staticmethod
    def get_new_cronjob(old_cronjob_list: list, new_cronjob_list: list):
        old_cj_names = [cj['name'] for cj in old_cronjob_list]
        for cj in new_cronjob_list:
            if cj['name'] not in old_cj_names:
                return cj
        return {}

    def test_expected_scan_result(self, containers_cve: dict):
        expected_results = self.create_vulnerabilities_expected_results(
            expected_results=self.test_obj.get_arg('expected_results'))
        failed_paths = []
        for container_name, cve_list in expected_results.items():
            assert container_name in containers_cve.keys(), \
                f"Expect to receive {container_name} in results_details from backend"
            for cve in cve_list:
                if cve not in containers_cve[container_name].keys():
                    failed_paths.append(f"{container_name} -> {cve}")

        assert not failed_paths, 'Expect the data from backend would not fail less CVEs then the expected results.\n' \
                                 f'in the following entries is happened:\nfailed_paths: {failed_paths}\n containers_cve: {containers_cve}'
